# Spec Reuse Feature

## Overview

The `--reuse-spec` flag allows you to reuse existing specifications from Cortex instead of regenerating them, saving both time and API costs.

## Cost Savings

- **First run (generate spec)**: $0.03-0.05 (Opus) or $0.0001-0.0005 (GPT-4o-mini)
- **Subsequent runs (reuse spec)**: $0.00

For a benchmark of 100 problems with 3 model comparisons each:
- Without reuse: 300 spec generations = $9-$15
- With reuse: 100 spec generations = $3-$5
- **Savings: $6-$10 (60% reduction in spec costs)**

## Usage Examples

### Example 1: First Run - Generate Spec

```bash
# Generate spec with Opus (high quality, $0.03-0.05)
poetry run koderz run --problem-id "HumanEval/0" \
  --frontier-spec-model "claude-opus-4-5" \
  --local-model "codellama:70b"
```

Output:
```
Phase 1: Generating spec with claude-opus-4-5...
  Spec generated (cost: $0.0342)
  Stored in cortex
```

### Example 2: Second Run - Reuse Spec

```bash
# Reuse the spec, test with different iteration model
poetry run koderz run --problem-id "HumanEval/0" \
  --local-model "gpt-4o-mini" \
  --reuse-spec
```

Output:
```
Phase 1: Looking for existing spec for HumanEval/0...
  Found existing spec (generated by claude-opus-4-5)
  Reusing spec (cost: $0.00 - saved!)
```

### Example 3: Compare Multiple Models with Same Spec

```bash
# Run 1: Local model
poetry run koderz run --problem-id "HumanEval/0" \
  --frontier-spec-model "claude-opus-4-5" \
  --local-model "codellama:70b"

# Run 2: Small frontier (reuse spec)
poetry run koderz run --problem-id "HumanEval/0" \
  --local-model "gpt-4o-mini" \
  --reuse-spec

# Run 3: Claude Haiku (reuse spec)
poetry run koderz run --problem-id "HumanEval/0" \
  --local-model "claude-haiku-4-5" \
  --reuse-spec

# Run 4: Full frontier (reuse spec)
poetry run koderz run --problem-id "HumanEval/0" \
  --local-model "claude-sonnet-4-5" \
  --reuse-spec
```

**Cost comparison:**
- Without reuse: 4 × $0.03 = $0.12
- With reuse: $0.03 + 3 × $0.00 = $0.03
- **Savings: $0.09 (75%)**

### Example 4: Cheap Initial Spec + Multiple Tests

```bash
# Generate cheap spec with GPT-4o-mini (~$0.0002)
poetry run koderz run --problem-id "HumanEval/0" \
  --frontier-spec-model "gpt-4o-mini" \
  --local-model "gpt-4o-mini"

# Reuse for other models
poetry run koderz run --problem-id "HumanEval/0" \
  --local-model "codellama:70b" \
  --reuse-spec

poetry run koderz run --problem-id "HumanEval/0" \
  --local-model "claude-haiku-4-5" \
  --reuse-spec
```

**Total cost: ~$0.0002** (almost free!)

## How It Works

1. **First run without `--reuse-spec`**:
   - Generates spec using specified frontier model
   - Stores in Cortex with tags: `["experiment", "spec", exp_id, problem_id]`
   - Includes metadata: model, cost, timestamp

2. **Subsequent runs with `--reuse-spec`**:
   - Queries Cortex for memories matching problem ID + "spec" tag
   - Extracts spec from most recent matching memory
   - Uses the reused spec (cost = $0.00)
   - If no spec found, falls back to generating new one

3. **Spec Storage Format**:
   ```
   Title: "Experiment: HumanEval/0"
   Content: "Problem:\n{prompt}\n\nSpec:\n{spec_text}"
   Tags: ["experiment", "spec", exp_id, problem_id]
   Category: "custom"
   Importance: "high"
   ```

## When to Use --reuse-spec

✅ **Use when:**
- Comparing different models on same problem
- Re-running failed experiments
- Testing different checkpoint intervals
- Iterating on prompt engineering (non-spec changes)
- Running benchmarks with multiple model configurations

❌ **Don't use when:**
- You want a fresh spec with different instructions
- Testing different spec generation models
- Problem requirements have changed
- First time running a problem

## Querying Stored Specs

### View all stored specs:
```bash
poetry run python -c "
import asyncio
from koderz.cortex.client import CortexClient
import os

async def list_specs():
    cortex = CortexClient(os.getenv('CORTEX_PATH'))
    memories = await cortex.recall(
        query='spec',
        category='custom',
        limit=20
    )
    for m in memories:
        if 'spec' in m.get('tags', []):
            print(f\"Problem: {[t for t in m['tags'] if 'HumanEval' in t][0]}\")
            print(f\"  Model: {m.get('metadata', {}).get('model', 'unknown')}\")
            print(f\"  Cost: \${m.get('metadata', {}).get('cost', 0):.4f}\")
            print(f\"  Date: {m.get('metadata', {}).get('timestamp', 'unknown')}\")
            print()

asyncio.run(list_specs())
"
```

### Direct SQLite query:
```bash
sqlite3 ~/.claude-cortex/memories.db \
  "SELECT title, 
          json_extract(metadata, '$.model') as model,
          json_extract(metadata, '$.cost') as cost,
          created_at 
   FROM memories 
   WHERE tags LIKE '%spec%' 
   ORDER BY created_at DESC 
   LIMIT 10;"
```

## Best Practices

1. **Generate once with high-quality model**:
   ```bash
   # Generate with Opus for best specs
   poetry run koderz run --problem-id "HumanEval/0" \
     --frontier-spec-model "claude-opus-4-5" \
     --local-model "codellama:70b"
   ```

2. **Reuse for all subsequent experiments**:
   ```bash
   # Test all other models with --reuse-spec
   for model in gpt-4o-mini claude-haiku-4-5 claude-sonnet-4-5; do
     poetry run koderz run --problem-id "HumanEval/0" \
       --local-model "$model" \
       --reuse-spec
   done
   ```

3. **Use cheap specs for quick prototyping**:
   ```bash
   # Generate with GPT-4o-mini for rapid testing
   poetry run koderz run --problem-id "HumanEval/0" \
     --frontier-spec-model "gpt-4o-mini" \
     --local-model "gpt-4o-mini"
   ```

## Implementation Details

**Files modified:**
- `koderz/cli.py`: Added `--reuse-spec` flag
- `koderz/orchestrator.py`: Added spec reuse logic with Cortex query

**Lines of code:** ~40 lines added

**Memory query logic:**
```python
memories = await cortex.recall(
    query=f"{problem_id} spec",
    category="custom",
    limit=5
)

# Find memory with matching tags
for memory in memories:
    if "spec" in memory.get("tags", []) and problem_id in memory.get("tags", []):
        # Extract and reuse spec
        spec_text = content.split("\n\nSpec:\n", 1)[1]
        spec_result = {"spec": spec_text, "cost": 0.0}
        break
```

## Troubleshooting

**Problem: "No existing spec found"**
- Check if you've run the problem before
- Verify CORTEX_PATH is set correctly
- Query Cortex directly to confirm spec exists

**Problem: Reused spec seems outdated**
- Run without `--reuse-spec` to generate fresh spec
- Old specs are never auto-deleted (by design)

**Problem: Want to force regeneration**
- Simply omit the `--reuse-spec` flag
- Or delete old specs from Cortex database

## Summary

The `--reuse-spec` feature enables:
- ✅ **60-75% cost savings** on multi-model experiments
- ✅ **Faster iterations** (no spec generation wait)
- ✅ **Consistent comparisons** (same spec across models)
- ✅ **Zero-cost re-runs** for debugging

Perfect for benchmarking, model comparison, and cost-effective experimentation!
